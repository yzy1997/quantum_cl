{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6aa768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 12:54:52.705664: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-09 12:54:52.745789: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-09 12:54:52.758062: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-09 12:54:52.784183: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-09 12:54:55.939810: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/yangz2/anaconda3/envs/quan_cl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "量子电路结构:\n",
      "使用设备: cuda:2\n",
      "训练经验数量: 5\n",
      "测试经验数量: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangz2/anaconda3/envs/quan_cl/lib/python3.10/site-packages/avalanche/training/templates/base.py:468: PositionalArgumentsDeprecatedWarning: Avalanche is transitioning to strategy constructors that accept named (keyword) arguments only. This is done to ensure that there is no confusion regarding the meaning of each argument (strategies can have many arguments). Your are passing 3 positional arguments to the ER_ACE.__init__ method. Consider passing them as names arguments. The ability to pass positional arguments will be removed in the future.\n",
      "  warnings.warn(error_str, category=PositionalArgumentsDeprecatedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型参数数量: 1243554\n",
      "Starting training...\n",
      "\n",
      "--- Training on experience 0 ---\n",
      "Classes in this experience: [2, 3]\n",
      "Number of samples: 12089\n",
      "-- >> Start of training phase << --\n",
      " 49%|████▉     | 47/95 [01:07<01:05,  1.37s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 238\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(experience\u001b[38;5;241m.\u001b[39mdataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# 训练当前经验\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m \u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperience\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Evaluating after experience \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperience\u001b[38;5;241m.\u001b[39mcurrent_experience\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    241\u001b[0m results \u001b[38;5;241m=\u001b[39m strategy\u001b[38;5;241m.\u001b[39meval(benchmark\u001b[38;5;241m.\u001b[39mtest_stream)\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/avalanche/training/templates/base_sgd.py:211\u001b[0m, in \u001b[0;36mBaseSGDTemplate.train\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    205\u001b[0m     experiences: Union[TDatasetExperience, Iterable[TDatasetExperience]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    210\u001b[0m ):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_streams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mget_last_metrics()\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/avalanche/training/templates/base.py:163\u001b[0m, in \u001b[0;36mBaseTemplate.train\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperience \u001b[38;5;129;01min\u001b[39;00m experiences_list:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_training_exp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_streams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training_exp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/avalanche/training/templates/base_sgd.py:337\u001b[0m, in \u001b[0;36mBaseSGDTemplate._train_exp\u001b[0;34m(self, experience, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_training_epoch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/avalanche/training/supervised/er_ace.py:126\u001b[0m, in \u001b[0;36mER_ACE.training_epoch\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmb_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmb_buffer_out \u001b[38;5;241m=\u001b[39m avalanche_forward(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmb_buffer_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmb_buffer_tid\n\u001b[1;32m    130\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/avalanche/training/templates/problem_type/supervised_problem.py:47\u001b[0m, in \u001b[0;36mSupervisedProblem.forward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the model's output given the current mini-batch.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mavalanche_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmb_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmb_task_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/avalanche/models/utils.py:22\u001b[0m, in \u001b[0;36mavalanche_forward\u001b[0;34m(model, x, task_labels)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model(x, task_labels)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# no task labels\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[1], line 158\u001b[0m, in \u001b[0;36mAngleEncodingQuantumNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    155\u001b[0m input_vector \u001b[38;5;241m=\u001b[39m selected_features[i]\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# 执行量子电路\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m q_out \u001b[38;5;241m=\u001b[39m \u001b[43mquantum_net_angle\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m q_out_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(q_out, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    160\u001b[0m quantum_out\u001b[38;5;241m.\u001b[39mappend(q_out_tensor)\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/workflow/qnode.py:905\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mcapture\u001b[38;5;241m.\u001b[39menabled():\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m capture_qnode(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/workflow/qnode.py:881\u001b[0m, in \u001b[0;36mQNode._impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# Calculate the classical jacobians if necessary\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_program\u001b[38;5;241m.\u001b[39mset_classical_component(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[0;32m--> 881\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiff_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/workflow/execution.py:232\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, diff_method, interface, transform_program, inner_transform, config, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, device_vjp, mcm_config, gradient_fn)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform_program\u001b[38;5;241m.\u001b[39mis_informative:\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m post_processing(tapes)\n\u001b[0;32m--> 232\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m post_processing(results)\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/workflow/run.py:333\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(tapes, device, config, inner_transform_program)\u001b[0m\n\u001b[1;32m    330\u001b[0m         params \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mget_parameters(trainable_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    331\u001b[0m         tape\u001b[38;5;241m.\u001b[39mtrainable_params \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mget_trainable_indices(params)\n\u001b[0;32m--> 333\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mml_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecute_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjpc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:236\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, execute_fn, jpc, device)\u001b[0m\n\u001b[1;32m    228\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mextend(tape\u001b[38;5;241m.\u001b[39mget_parameters())\n\u001b[1;32m    230\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(tapes),\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecute_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m: execute_fn,\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpc\u001b[39m\u001b[38;5;124m\"\u001b[39m: jpc,\n\u001b[1;32m    234\u001b[0m }\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExecuteTapes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:89\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_apply\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_apply\u001b[39m(\u001b[38;5;241m*\u001b[39minp):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Inputs already flat\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     out_struct_holder \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 89\u001b[0m     flat_out \u001b[38;5;241m=\u001b[39m \u001b[43morig_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_struct_holder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(flat_out, out_struct_holder[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:93\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_forward\u001b[0;34m(ctx, out_struct_holder, *inp)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_forward\u001b[39m(ctx, out_struct_holder, \u001b[38;5;241m*\u001b[39minp):\n\u001b[0;32m---> 93\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43morig_fw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     flat_out, out_struct \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_flatten(out)\n\u001b[1;32m     95\u001b[0m     ctx\u001b[38;5;241m.\u001b[39m_out_struct \u001b[38;5;241m=\u001b[39m out_struct\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/workflow/interfaces/torch.py:158\u001b[0m, in \u001b[0;36mExecuteTapes.forward\u001b[0;34m(ctx, kwargs, *parameters)\u001b[0m\n\u001b[1;32m    155\u001b[0m ctx\u001b[38;5;241m.\u001b[39mtapes \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    156\u001b[0m ctx\u001b[38;5;241m.\u001b[39mjpc \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 158\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexecute_fn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# if any input tensor uses the GPU, the output should as well\u001b[39;00m\n\u001b[1;32m    161\u001b[0m ctx\u001b[38;5;241m.\u001b[39mtorch_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/workflow/run.py:244\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[0;34m(tapes)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_execute\u001b[39m(tapes: QuantumScriptBatch) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResultBatch:\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execution that occurs within a ML framework boundary.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    Closure Variables:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m        device (qml.devices.Device): a Pennylane device\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m     transformed_tapes, transform_post_processing \u001b[38;5;241m=\u001b[39m \u001b[43minner_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transformed_tapes:\n\u001b[1;32m    247\u001b[0m         results \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mexecute(transformed_tapes, execution_config\u001b[38;5;241m=\u001b[39mexecution_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/transforms/core/transform_program.py:580\u001b[0m, in \u001b[0;36mTransformProgram.__call__\u001b[0;34m(self, tapes)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m argnums \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    579\u001b[0m     tape\u001b[38;5;241m.\u001b[39mtrainable_params \u001b[38;5;241m=\u001b[39m argnums[j]\n\u001b[0;32m--> 580\u001b[0m new_tapes, fn \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m execution_tapes\u001b[38;5;241m.\u001b[39mextend(new_tapes)\n\u001b[1;32m    583\u001b[0m fns\u001b[38;5;241m.\u001b[39mappend(fn)\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/transforms/broadcast_expand.py:134\u001b[0m, in \u001b[0;36mbroadcast_expand\u001b[0;34m(tape)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@transform\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast_expand\u001b[39m(tape: QuantumScript) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[QuantumScriptBatch, PostprocessingFn]:\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Expand a broadcasted tape into multiple tapes\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    and a function that stacks and squeezes the results.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    tensor([0.98006658, 0.82533561, 0.54030231], requires_grad=True)\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (tape,), null_postprocessing\n\u001b[1;32m    137\u001b[0m     has_postselect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    138\u001b[0m         op\u001b[38;5;241m.\u001b[39mpostselect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m tape\u001b[38;5;241m.\u001b[39moperations \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, MidMeasureMP)\n\u001b[1;32m    139\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/tape/qscript.py:322\u001b[0m, in \u001b[0;36mQuantumScript.batch_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"The batch size of the quantum script inferred from the batch sizes\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03mof the used operations for parameter broadcasting.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m    int or None: The batch size of the quantum script if present, else ``None``.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_size \u001b[38;5;129;01mis\u001b[39;00m _UNSET_BATCH_SIZE:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_size\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/tape/qscript.py:555\u001b[0m, in \u001b[0;36mQuantumScript._update_batch_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m candidate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperations:\n\u001b[0;32m--> 555\u001b[0m     op_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/operation.py:1259\u001b[0m, in \u001b[0;36mOperator.batch_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Batch size of the operator if it is used with broadcasted parameters.\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m \n\u001b[1;32m   1250\u001b[0m \u001b[38;5;124;03mThe ``batch_size`` is determined based on ``ndim_params`` and the provided parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;124;03m    int or None: Size of the parameter broadcasting dimension if present, else ``None``.\u001b[39;00m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_size \u001b[38;5;129;01mis\u001b[39;00m _UNSET_BATCH_SIZE:\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_batching\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_size\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/operation.py:1182\u001b[0m, in \u001b[0;36mOperator._check_batching\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m-> 1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;66;03m# if the batch dimension is unknown, then skip the validation\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;66;03m# this happens when a tensor with a partially known shape is passed, e.g. (None, 12),\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;66;03m# typically during compilation of a function decorated with jax.jit or tf.function\u001b[39;00m\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndim_params \u001b[38;5;241m=\u001b[39m ndims\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/pennylane/operation.py:1182\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m-> 1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mshape(p)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params):\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;66;03m# if the batch dimension is unknown, then skip the validation\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;66;03m# this happens when a tensor with a partially known shape is passed, e.g. (None, 12),\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;66;03m# typically during compilation of a function decorated with jax.jit or tf.function\u001b[39;00m\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndim_params \u001b[38;5;241m=\u001b[39m ndims\n",
      "File \u001b[0;32m~/anaconda3/envs/quan_cl/lib/python3.10/site-packages/autoray/autoray.py:80\u001b[0m, in \u001b[0;36mdo\u001b[0;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Do function named ``fn`` on ``(*args, **kwargs)``, peforming single\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03mdispatch to retrieve ``fn`` based on whichever library defines the class of\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mthe ``args[0]``, or the ``like`` keyword argument if specified.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    <tf.Tensor: id=91, shape=(3, 3), dtype=float32>\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m backend \u001b[38;5;241m=\u001b[39m _choose_backend(fn, args, kwargs, like\u001b[38;5;241m=\u001b[39mlike)\n\u001b[0;32m---> 80\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[43mget_lib_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from avalanche.benchmarks.classic import SplitMNIST\n",
    "from avalanche.training import Naive\n",
    "from avalanche.training.supervised import ER_ACE\n",
    "from avalanche.training.plugins import EvaluationPlugin, LRSchedulerPlugin\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, \\\n",
    "accuracy_metrics, loss_metrics, timing_metrics, cpu_usage_metrics, \\\n",
    "confusion_matrix_metrics, disk_usage_metrics\n",
    "from avalanche.logging import InteractiveLogger\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# 忽略一些不重要的警告\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.optim.lr_scheduler\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pennylane\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# 设置随机种子确保可复现性\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# ================== 修改后的量子电路参数 ==================\n",
    "n_qubits = 10  # 10个量子比特可以表示1024维状态 (2^10=1024)，足以处理784维输入\n",
    "q_depth = 3    # 简化的量子深度（原为10）\n",
    "q_delta = 0.5  # 参数初始化范围（增大以改善梯度）\n",
    "train_epochs = 20  # 每个经验的训练轮次\n",
    "\n",
    "# 量子计算设备设置\n",
    "dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "\n",
    "# ================== 修改后的量子电路定义 ==================\n",
    "def entangling_layer(n):\n",
    "    \"\"\"简化的线性链式纠缠层\"\"\"\n",
    "    for i in range(n-1):\n",
    "        qml.CZ(wires=[i, i+1])\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\", diff_method=\"parameter-shift\")\n",
    "def quantum_net_angle(input_features, q_weights):\n",
    "    \"\"\"\n",
    "    使用角度编码的量子电路\n",
    "    输入: \n",
    "      input_features - 长度为n_qubits的特征向量\n",
    "      q_weights - 量子权重参数 (q_depth, n_qubits)\n",
    "    \"\"\"\n",
    "    # 角度编码 - 将经典特征映射到量子旋转角度\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(input_features[i] * np.pi, wires=i)  # 缩放特征到[0, π]范围\n",
    "    \n",
    "    # 应用量子层\n",
    "    for layer in range(q_depth):\n",
    "        # 参数化旋转\n",
    "        for i in range(n_qubits):\n",
    "            qml.RY(q_weights[layer, i], wires=i)\n",
    "        \n",
    "        # 简化的纠缠层\n",
    "        entangling_layer(n_qubits)\n",
    "    \n",
    "    # 测量\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "# 可视化量子电路\n",
    "print(\"量子电路结构:\")\n",
    "qml.drawer.use_style(\"pennylane\")\n",
    "# 使用784维输入进行可视化\n",
    "fig, ax = qml.draw_mpl(quantum_net_angle)(torch.randn(n_qubits), torch.randn(q_depth, n_qubits))\n",
    "plt.savefig(\"/home/yangz2/code/quantum_cl/results/figs/circuit3_angle.png\")\n",
    "plt.close()\n",
    "\n",
    "device = \"cuda:2\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# ================== 修改后的量子-经典混合网络 ==================\n",
    "class AngleEncodingQuantumNet(nn.Module):\n",
    "    def __init__(self, n_qubits, q_depth, q_delta, num_classes=10):  # 固定为10类\n",
    "        \"\"\"\n",
    "        初始化:\n",
    "          num_classes - 初始类别数（设置为10）\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.q_depth = q_depth\n",
    "        \n",
    "        # 预处理网络 - 输出784维向量\n",
    "        self.pre_net = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 28x28 -> 14x14\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 14x14 -> 7x7\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 7 * 7, 784),  # 输出784维向量\n",
    "            nn.Tanh()  # 限制在[-1, 1]范围\n",
    "        )\n",
    "        \n",
    "        # 特征选择层 - 从784维中选择最重要的n_qubits个特征\n",
    "        self.feature_selector = nn.Linear(784, n_qubits)\n",
    "        \n",
    "        # 量子参数\n",
    "        self.q_params = nn.Parameter(q_delta * torch.randn(q_depth, n_qubits))\n",
    "        \n",
    "        # 后处理网络 - 固定为10个输出\n",
    "        self.post_net = nn.Sequential(\n",
    "            nn.Linear(n_qubits, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "        \n",
    "        # 初始化权重\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        # 特征提取 - 输出784维向量\n",
    "        features = self.pre_net(x)\n",
    "        \n",
    "        # 选择最重要的n_qubits个特征\n",
    "        selected_features = self.feature_selector(features)\n",
    "        \n",
    "        # 量子计算 - 处理批处理\n",
    "        batch_size = x.size(0)\n",
    "        quantum_out = []\n",
    "        \n",
    "        # 对每个样本单独处理\n",
    "        for i in range(batch_size):\n",
    "            # 获取当前样本的特征向量\n",
    "            input_vector = selected_features[i]\n",
    "            \n",
    "            # 执行量子电路\n",
    "            q_out = quantum_net_angle(input_vector, self.q_params)\n",
    "            q_out_tensor = torch.tensor(q_out, device=device, dtype=torch.float32)\n",
    "            quantum_out.append(q_out_tensor)\n",
    "        \n",
    "        quantum_out = torch.stack(quantum_out)\n",
    "        \n",
    "        # 分类\n",
    "        return self.post_net(quantum_out)\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    # transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST的标准归一化\n",
    "])\n",
    "\n",
    "# 创建SplitMNIST基准 - 使用全局类别标签\n",
    "benchmark = SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=False,\n",
    "    train_transform=transform,\n",
    "    eval_transform=transform,\n",
    "    class_ids_from_zero_in_each_exp=False  # 使用全局类别标签\n",
    ")\n",
    "\n",
    "print(f\"训练经验数量: {len(benchmark.train_stream)}\")\n",
    "print(f\"测试经验数量: {len(benchmark.test_stream)}\")\n",
    "\n",
    "# 创建模型 - 固定为10个输出类\n",
    "model = AngleEncodingQuantumNet(n_qubits, q_depth, q_delta, num_classes=10).to(device)\n",
    "print(f\"模型参数数量: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "\n",
    "# 优化器和损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # 增大学习率\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # 使用CrossEntropyLoss\n",
    "\n",
    "# 评估设置\n",
    "interactive_logger = InteractiveLogger()\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    timing_metrics(epoch=True, epoch_running=True),\n",
    "    cpu_usage_metrics(experience=True),\n",
    "    forgetting_metrics(experience=True, stream=True),\n",
    "    confusion_matrix_metrics(num_classes=10, save_image=True, stream=True),\n",
    "    disk_usage_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loggers=[interactive_logger]\n",
    ")\n",
    "\n",
    "\n",
    "# 8. 添加学习率调度器\n",
    "lr_scheduler = StepLR(optimizer, step_size=3, gamma=0.7)\n",
    "lr_plugin = LRSchedulerPlugin(lr_scheduler)\n",
    "\n",
    "# 9. 创建持续学习策略\n",
    "strategy = ER_ACE(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_mb_size=256,           # 训练批次大小\n",
    "    eval_mb_size=512,            # 评估批次大小\n",
    "    train_epochs=30,             # 增加训练轮数\n",
    "    plugins=[lr_plugin],\n",
    "    evaluator=eval_plugin,\n",
    "    device=device,\n",
    "    # eval_every=1                 # 每个epoch后都评估\n",
    ")\n",
    "\n",
    "# 训练和评估\n",
    "save_dir = \"/home/yangz2/code/quantum_cl/results/list\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "task_accuracies = []\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for experience_idx, experience in enumerate(benchmark.train_stream):\n",
    "    print(f\"\\n--- Training on experience {experience.current_experience} ---\")\n",
    "    print(f\"Classes in this experience: {experience.classes_in_this_experience}\")\n",
    "    print(f\"Number of samples: {len(experience.dataset)}\")\n",
    "    \n",
    "    # 训练当前经验\n",
    "    strategy.train(experience)\n",
    "    \n",
    "    print(f\"--- Evaluating after experience {experience.current_experience} ---\")\n",
    "    results = strategy.eval(benchmark.test_stream)\n",
    "    task_accuracies.append(results)\n",
    "    \n",
    "    # 保存中间结果\n",
    "    with open(os.path.join(save_dir, f\"splitmnist_erace_ours_qbit{n_qubits}_qdepth{q_depth}_tepoch{train_epochs}_interim_results_exp_{experience.current_experience}.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(task_accuracies, f)\n",
    "    \n",
    "    # 打印当前准确率\n",
    "    acc_key = 'Top1_Acc_Stream/eval_phase/test_stream/Task000'\n",
    "    if acc_key in results:\n",
    "        acc = results[acc_key]\n",
    "        print(f\"Global accuracy after experience {experience.current_experience}: {acc*100:.2f}%\")\n",
    "    else:\n",
    "        # 列出所有键以便调试\n",
    "        print(f\"Error: Accuracy key not found. Available keys: {list(results.keys())}\")\n",
    "        # 尝试找到类似的键\n",
    "        for key in results.keys():\n",
    "            if \"Acc_Stream\" in key:\n",
    "                acc = results[key]\n",
    "                print(f\"Found alternative accuracy key: {key} = {acc*100:.2f}%\")\n",
    "                break\n",
    "        else:\n",
    "            acc = 0.0\n",
    "            print(\"No accuracy metric found in results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存最终结果\n",
    "with open(os.path.join(save_dir, f\"splitmnist_erace_ours_qbit{n_qubits}_qdepth{q_depth}_tepoch{train_epochs}.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(task_accuracies, f)\n",
    "\n",
    "print(\"✔ Training and evaluation completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quan_cl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# import torch
# import torch.nn as nn
# import torch.optim as optim
# import matplotlib.pyplot as plt
# from avalanche.benchmarks import SplitMNIST
# from avalanche.models import SimpleMLP
# from avalanche.training import EWC
# from avalanche.training.plugins import EvaluationPlugin
# from avalanche.evaluation.metrics import accuracy_metrics
# from avalanche.logging import InteractiveLogger
# import os
# import pickle

# # è®¾ç½®è®¾å¤‡
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# # SplitMNIST æ•°æ®é›†
# benchmark = SplitMNIST(n_experiences=5, return_task_id=False)

# # æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°
# model = SimpleMLP(num_classes=10)
# optimizer = optim.SGD(model.parameters(), lr=0.01)
# criterion = nn.CrossEntropyLoss()

# # æ—¥å¿—å™¨å’Œè¯„ä¼°å™¨
# interactive_logger = InteractiveLogger()

# eval_plugin = EvaluationPlugin(
#     accuracy_metrics(stream=True),
#     loggers=[interactive_logger]
# )

# strategy = EWC(
#     model=model,
#     optimizer=optimizer,
#     criterion=criterion,
#     ewc_lambda=0.4,
#     train_epochs=1,
#     device=device,
#     evaluator=eval_plugin
# )

# # ğŸ“Œ ç”¨äºè®°å½•æ¯ä¸ªä»»åŠ¡çš„å‡†ç¡®ç‡
# task_accuracies = []

# # å¼€å§‹è®­ç»ƒæ¯ä¸ª experience
# for experience in benchmark.train_stream:
#     print(f"\n--- Training on experience {experience.current_experience} ---")
#     strategy.train(experience)

#     print("--- Evaluating on test stream ---")
#     results = strategy.eval(benchmark.test_stream)

#     # æå–å¹¶è®°å½• accuracy
#     task_accuracies.append(results)

# # Define the file path
# file_path = "/home/yangz2/code/quantum_cl/results/list/try.pkl"

# # Create directories if they don't exist
# os.makedirs(os.path.dirname(file_path), exist_ok=True)  # <-- Add this line   

# # å­˜å‚¨åˆ°æ–‡ä»¶
# with open(file_path, "wb") as f:
#     pickle.dump([task_accuracies], f)  
    
# with open(file_path, "rb") as f:
#     task_accuracies = pickle.load(f) 
# # âœ… ç»˜å›¾
# # éå† results æå– Loss_Exp æ•°æ®

# x= []  # x è½´æ•°æ®
# num_experiences = 5  # SplitMNIST æœ‰ 5 ä¸ª experienceï¼Œä½†æ¯ä¸ª experience å¯¹åº” 4 æ¬¡ eval
# count = 1  # ç”¨äºæ ‡è®°ç»éªŒç¼–å·
# loss_values = []
# for train_idx, result in enumerate(results):  # éå†5æ¬¡è®­ç»ƒçš„ç»“æœ
#     for exp_id in range(0, num_experiences):  # æ¯æ¬¡è®­ç»ƒå¯¹åº”4æ¬¡ evalï¼ˆExp001 åˆ° Exp004ï¼‰
#         key = f"Loss_Exp/eval_phase/test_stream/Task000/Exp00{exp_id}"
#         loss = result.get(key, None)
#         if loss is not None:  # ç¡®ä¿é”®å­˜åœ¨
#             loss_values.append(loss)
#             x.append(count)  # x è½´è¿ç»­ç¼–å·
#             count += 1

# # éå† results æå– Top1_Acc_Exp æ•°æ®
# top1_acc_values = []
# for train_idx, result in enumerate(results):  # éå†5æ¬¡è®­ç»ƒçš„ç»“æœ
#     for exp_id in range(0, num_experiences):  # æ¯æ¬¡è®­ç»ƒå¯¹åº”4æ¬¡ evalï¼ˆExp001 åˆ° Exp004ï¼‰
#         key = f"Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp00{exp_id}"
#         top1_acc = result.get(key, None)
#         if top1_acc is not None:  # ç¡®ä¿é”®å­˜åœ¨
#             top1_acc_values.append(top1_acc)

# # éå† resutls ä¸­çš„ Forgetting æ•°æ®, ä½†æ˜¯æ˜¯æ¯ä¸ªstreamçš„Forgetting
# forgetting_values = []
# for train_idx, result in enumerate(results):  # éå†5æ¬¡è®­ç»ƒçš„ç»“æœ
#     for exp_id in range(0, num_experiences):  # æ¯æ¬¡è®­ç»ƒå¯¹åº”4æ¬¡ evalï¼ˆExp001 åˆ° Exp004ï¼‰
#         key = f"StreamForgetting/eval_phase/test_stream"
#         forgetting = result.get(key, None)
#         if forgetting is not None:  # ç¡®ä¿é”®å­˜åœ¨
#             forgetting_values.append(forgetting)


# # ç»˜åˆ¶å›¾å½¢
# plt.figure(figsize=(20, 6))
# plt.plot(x, loss_values, marker='o', linestyle='-', color='b', label='Loss_Exp')
# plt.title("Loss over n_experience**2 Evaluations After n_experience Training Phases")
# plt.xlabel("Evaluation Index")
# plt.ylabel("Loss Value")
# plt.xticks(range(1, len(x) + 1))  # è®¾ç½® x è½´åˆ»åº¦
# plt.grid(True)
# plt.legend("splitminist_EWC_qbit8_qdepth10_loss")
# plt.tight_layout()
# plt.savefig("/home/yangz2/code/quantum_cl/results/figs/loss_try.png")

# plt.figure(figsize=(20, 6))
# plt.plot(x, top1_acc_values, marker='o', linestyle='-', color='r', label='Top1_Acc_Exp')
# plt.title("Top1_Acc over n_experience**2 Evaluations After n_experience Training Phases")
# plt.xlabel("Evaluation Index")
# plt.ylabel("Top1_Acc Value")
# plt.xticks(range(1, len(x) + 1))  # è®¾ç½® x è½´åˆ»åº¦
# plt.grid(True)
# plt.legend("splitminist_EWC_qbit8_qdepth10_acc")
# plt.tight_layout()
# plt.savefig("/home/yangz2/code/quantum_cl/results/figs/acc_try.png")

# plt.figure(figsize=(20, 6))
# plt.plot(range(1, len(forgetting_values) + 1), forgetting_values, marker='o', linestyle='-', color='g', label='StreamForgetting')
# plt.title("StreamForgetting over n_experience**2 Evaluations After n_experience Training Phases")
# plt.xlabel("Evaluation Index")
# plt.ylabel("StreamForgetting Value")
# plt.xticks(range(1, len(forgetting_values) + 1))  # è®¾ç½® x è½´åˆ»åº¦
# plt.grid(True)
# plt.legend("splitminist_EWC_qbit8_qdepth10_forget")
# plt.tight_layout()
# plt.savefig("/home/yangz2/code/quantum_cl/results/figs/forget_try.png")


# In[ ]:


# with open(file_path, "rb") as f:
#     task_accuracies = pickle.load(f) 
    
# print(task_accuracies)


# In[1]:


import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt
import pennylane as qml
from pennylane.qnn import TorchLayer
from torchvision import transforms

from avalanche.benchmarks.classic import SplitMNIST
from avalanche.training import Naive
from avalanche.training.plugins import EvaluationPlugin,SupervisedPlugin, ReplayPlugin
from avalanche.evaluation.metrics import forgetting_metrics, \
accuracy_metrics, loss_metrics, timing_metrics, cpu_usage_metrics, \
confusion_matrix_metrics, disk_usage_metrics
from avalanche.logging import InteractiveLogger
import pickle
import os


# In[7]:


# -----------------------------
# 1. Quantum Circuit Definition (Multi-layer)
# -----------------------------
n_qubits = 10
input_dim = 2**n_qubits  # 28 x 28 MNIST
n_layers = 10  # âœ… Now actually used
dev = qml.device("lightning.qubit", wires=n_qubits)

def quantum_circuit(inputs, weights):
    # ğŸ’¡ Clamp é™åˆ¶è¾“å…¥èŒƒå›´ï¼Œé˜²æ­¢æç«¯å½’ä¸€åŒ–åæŒ¯å¹…å¾ˆå°æˆ–å¾ˆå¤§
    inputs = qml.math.clip(inputs, -1.0, 1.0)
    # 1. Amplitude embeddingï¼ˆå¿…é¡» L2 å½’ä¸€åŒ–ï¼‰
    qml.AmplitudeEmbedding(inputs, wires=range(n_qubits), normalize=True)
    # weights: [n_layers, n_qubits, 2]
    for layer in range(n_layers):
        for i in range(n_qubits):
            qml.RX(weights[layer, i, 1], wires=i)
            qml.RZ(weights[layer, i, 0], wires=i)

        # Entanglement layer (odd-even alternating)
        for i in range(1, n_qubits - 1, 2):
            qml.CNOT(wires=[i, i + 1])
        for i in range(0, n_qubits - 1, 2):
            qml.CNOT(wires=[i, i + 1])
        for i in range(1, n_qubits - 1, 2):
            qml.CNOT(wires=[i, i + 1])
        for i in range(0, n_qubits - 1, 2):
            qml.CNOT(wires=[i, i + 1])
        for i in range(n_qubits):
            qml.RZ(weights[layer, i, 0], wires=i)
            qml.RX(weights[layer, i, 1], wires=i)

    return qml.expval(qml.PauliZ(0))

qml.drawer.use_style("pennylane")
# è¾“å…¥ï¼š8ä¸ªé‡å­æ¯”ç‰¹
inputs = torch.randn(2 ** n_qubits)

# æƒé‡ï¼š10 å±‚ï¼Œæ¯å±‚ 8 æ¯”ç‰¹ï¼Œæ¯æ¯”ç‰¹ä¸¤ä¸ªå‚æ•°ï¼ˆRZ, RXï¼‰
weights = torch.randn(n_layers, n_qubits, 2)

# ç»˜åˆ¶ç”µè·¯
fig, ax = qml.draw_mpl(quantum_circuit)(inputs, weights)
plt.show()

# -----------------------------
# 2. TorchLayer + PyTorch Model
# -----------------------------
weight_shapes = {"weights": (n_layers, n_qubits, 2)}
qnode = qml.QNode(quantum_circuit, dev, interface="torch")
qlayer = TorchLayer(qnode, weight_shapes)
with torch.no_grad():
    qlayer.weights.data = qlayer.weights.data * 0.1

class QuantumClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        self.q_layer = qlayer
        self.output = nn.Linear(1, 10)

    def forward(self, x):
        x = torch.nan_to_num(x, nan=0.0, posinf=1.0, neginf=-1.0)
        # æ·»åŠ epsilonå¹¶ç¡®ä¿å½’ä¸€åŒ–ç»´åº¦æ­£ç¡®
        x = F.normalize(x + 1e-8, p=2, dim=1)  # æ³¨æ„dim=1ï¼ˆbatchç»´åº¦ï¼‰
        x = self.q_layer(x)
        x = x.unsqueeze(1)  # ç¡®ä¿è¾“å‡ºå½¢çŠ¶åŒ¹é…
        x = self.output(x)
        return F.log_softmax(x, dim=1)


# In[ ]:


# -----------------------------
# 3. Data Transform (Only 8 pixels used)
# -----------------------------
def adjust_dimension(x):
    current_dim = x.shape[0]
    if current_dim < input_dim:
        # å¡«å……0åˆ°1024ç»´
        return F.pad(x, (0, input_dim - current_dim))
    elif current_dim > input_dim:
        # æˆªæ–­åˆ°1024ç»´
        return x[:input_dim]
    return x

transform = transforms.Compose([
    transforms.Lambda(lambda x: x.view(-1)),  # å±•å¹³
    transforms.Lambda(adjust_dimension),      # è°ƒæ•´ç»´åº¦
    transforms.Lambda(lambda x: torch.clamp(x, -1.0, 1.0)),
])

benchmark = SplitMNIST(n_experiences=5, return_task_id=False,
                       train_transform=transform, eval_transform=transform)

# -----------------------------
# 4. Avalanche EWC Strategy Setup
# -----------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = QuantumClassifier().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.NLLLoss()

interactive_logger = InteractiveLogger()
eval_plugin = EvaluationPlugin(
    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),
    loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),
    timing_metrics(epoch=True, epoch_running=True),
    cpu_usage_metrics(experience=True),
    forgetting_metrics(experience=True, stream=True),
    confusion_matrix_metrics(num_classes=10, save_image=True,
                             stream=True),
    disk_usage_metrics(minibatch=True, epoch=True, experience=True, stream=True),
    loggers=[interactive_logger]
)

# ä½¿ç”¨ERç­–ç•¥

replay_plugin = ReplayPlugin(
    mem_size=200,
    batch_size=32,      # æ¯ä¸ª minibatch ä¸­æ–°æ ·æœ¬çš„æ•°é‡
    batch_size_mem=32,  # æ¯ä¸ª minibatch ä¸­é‡æ”¾æ ·æœ¬çš„æ•°é‡
    task_balanced_dataloader=False
)

strategy = Naive(
    model=model,
    optimizer=optimizer,
    criterion=criterion,
    train_epochs=20,
    device=device,
    evaluator=eval_plugin,
    plugins=[replay_plugin]
)


class GradientClipPlugin(SupervisedPlugin):
    def before_backward(self, strategy, **kwargs):
        torch.nn.utils.clip_grad_norm_(strategy.model.parameters(), max_norm=1.0)

strategy.plugins.append(GradientClipPlugin())

# -----------------------------
# 5. Training & Accuracy Recording
# -----------------------------
task_accuracies = []

for experience in benchmark.train_stream:
    print(f"\n--- Training on experience {experience.current_experience} ---")
    strategy.train(experience)

    print("--- Evaluating on test stream ---")
    results = strategy.eval(benchmark.test_stream)

    task_accuracies.append(results)
 



# In[ ]:


# Define the file path
file_path = "/home/yangz2/code/quantum_cl/results/list/splitminist_ER_ocf_qbit10_qdepth10.pkl"

# Create directories if they don't exist
os.makedirs(os.path.dirname(file_path), exist_ok=True)  # <-- Add this line   
   


# In[ ]:


# å­˜å‚¨åˆ°æ–‡ä»¶
with open(file_path, "wb") as f:
    pickle.dump([task_accuracies], f)  


# In[ ]:


# file_path = "/home/yangz2/code/quantum_cl/results/list/splitminist_EWC_qbit8_qdepth10.pkl"
# with open(file_path, "rb") as f:
#     results = pickle.load(f)  
    
# print(type(results))
# print(results)


# In[ ]:


# import matplotlib.pyplot as plt

# # results = pickle.load(â€¦)  # å·²ç»åŠ è½½å¥½çš„ list of dict
# save_dir = "/home/yangz2/code/quantum_cl/results/figs"

# # 1) å‡†å¤‡æ¨ªè½´ï¼ˆexperience åºå·ï¼‰
# exp_idxs = list(range(1, len(results) + 1))

# # 2) ä» results ä¸­æå–ä¸‰æ¡æ›²çº¿
# accuracies  = [r['Top1_Acc_Stream/eval_phase/test_stream/Task000'] for r in results]
# losses      = [r['Loss_Stream/eval_phase/test_stream/Task000']      for r in results]
# forgettings = [r['StreamForgetting/eval_phase/test_stream']         for r in results]

# # 3) ç”» Accuracy
# plt.figure()
# plt.plot(exp_idxs, accuracies)
# plt.xlabel('Experience')
# plt.ylabel('Accuracy')
# plt.title('Accuracy over Experiences')
# plt.xticks(exp_idxs)
# plt.savefig(os.path.join(save_dir, "splitmnist_EWC_qbit8_qdepth4_tepoch40_acc.png"))

# # 4) ç”» Loss
# plt.figure()
# plt.plot(exp_idxs, losses)
# plt.xlabel('Experience')
# plt.ylabel('Loss')
# plt.title('Loss over Experiences')
# plt.xticks(exp_idxs)
# plt.savefig(os.path.join(save_dir, "splitmnist_EWC_qbit8_qdepth4_tepoch40_loss.png"))

# # 5) ç”» Forgetting
# plt.figure()
# plt.plot(exp_idxs, forgettings)
# plt.xlabel('Experience')
# plt.ylabel('Forgetting')
# plt.title('Forgetting over Experiences')
# plt.xticks(exp_idxs)
# plt.savefig(os.path.join(save_dir, "splitmnist_EWC_qbit8_qdepth4_tepoch40_forget.png"))


# In[ ]:


# key = "Top1_Acc_Stream/eval_phase/test_stream/Task000"
# top1_acc_values = [res.get(key, None) for res in results if key in res]

# x = list(range(1, len(top1_acc_values) + 1))

# plt.figure(figsize=(20, 6))
# plt.plot(x, top1_acc_values, marker='o', linestyle='-', color='r', label='Top1_Acc_Exp')
# plt.title("Top1_Acc over Evaluations After Training Phases")
# plt.xlabel("Evaluation Index")
# plt.ylabel("Top1_Acc Value")
# plt.xticks(x)  # è®¾ç½® x è½´åˆ»åº¦
# plt.grid(True)
# plt.legend()
# plt.tight_layout()
# plt.savefig(os.path.join(save_dir, "splitminist_EWC_qbit8_qdepth10_acc.png"))
# plt.show()

